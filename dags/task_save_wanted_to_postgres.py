import json
import pandas as pd
from airflow.providers.postgres.hooks.postgres import PostgresHook
from utils import load_json_data

def process_and_send_to_postgres(ti):
    """
    Airflow Task: ì—¬ëŸ¬ ì´ì „ Taskë“¤ì˜ ê²°ê³¼(JSON íŒŒì¼)ë¥¼ XComìœ¼ë¡œ ë°›ì•„
    ìµœì¢… ë°ì´í„°ë¥¼ ê°€ê³µí•œ í›„ PostgreSQL DBì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    # 1. ì´ì „ Taskë“¤ë¡œë¶€í„° íŒŒì¼ ê²½ë¡œë¥¼ XComìœ¼ë¡œ ë°›ì•„ì˜µë‹ˆë‹¤.
    clustered_path = ti.xcom_pull(task_ids='clustering_jobs_task', key='return_value')
    keyword_path = ti.xcom_pull(task_ids='tokenize_jobs_task', key='return_value')

    if not clustered_path or not keyword_path:
        raise ValueError("XComìœ¼ë¡œë¶€í„° í´ëŸ¬ìŠ¤í„°ë§ ë˜ëŠ” í† í°í™” ë°ì´í„° íŒŒì¼ ê²½ë¡œë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    print(f"í´ëŸ¬ìŠ¤í„°ë§ ë°ì´í„° ë¡œë“œ: {clustered_path}")
    print(f"í‚¤ì›Œë“œ ë°ì´í„° ë¡œë“œ: {keyword_path}")

    clustered_data = pd.DataFrame(load_json_data(clustered_path))
    keyword_data = pd.DataFrame(load_json_data(keyword_path))

    # 2. Airflow Connectionì„ ì‚¬ìš©í•˜ì—¬ PostgresHook ìƒì„±
    hook = PostgresHook(postgres_conn_id='postgres_jobs_db')

    # 3. DBì—ì„œ job_required_skills í…Œì´ë¸” ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    try:
        # Airflow Hookì˜ ê³µì‹ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        sql = "SELECT id, job_name FROM job_required_skills"
        job_required_skills = hook.get_pandas_df(sql=sql)
        print(f"âœ… DBì—ì„œ {len(job_required_skills)}ê°œì˜ ì§ë¬´ ì¹´í…Œê³ ë¦¬ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ğŸš¨ DBì—ì„œ 'job_required_skills' í…Œì´ë¸”ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

    # --- ë°ì´í„° ì „ì²˜ë¦¬ ë¡œì§ (ë³€ê²½ ì—†ìŒ) ---
    print("ë°ì´í„° ë³‘í•© ë° ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    merged_data = clustered_data.merge(keyword_data, on='id', how='left')
    job_required_skills.rename(columns={"id": "job_required_skill_id", 'job_name': 'representative_category'}, inplace=True)
    join_data = merged_data.merge(job_required_skills[["representative_category", "job_required_skill_id"]], on='representative_category', how='left')
    join_data.drop(columns=["representative_category", "job_category", "cluster"], inplace=True, errors="ignore")
    
    for col in ["required_skills", "preferred_skills", "main_tasks_skills"]:
        join_data[col] = join_data[col].apply(lambda x: json.dumps(x if isinstance(x, list) else []))
    join_data["address"] = join_data["address"].fillna("")
    
    target_columns = [
        'id', 'title', 'company_name', 'size', 'address', 'job_required_skill_id',
        'employment_type', 'applicant_type', 'posting_date', 'deadline',
        'main_tasks', 'qualifications', 'preferences', 'tech_stack',
        'required_skills', 'preferred_skills', 'main_tasks_skills'
    ]
    final_data = join_data[[col for col in target_columns if col in join_data.columns]]

    # --- DB ì €ì¥ ë¡œì§ (Hookì˜ ê³µì‹ ê¸°ëŠ¥ ì‚¬ìš©) ---
    try:
        # DBì— ì´ë¯¸ ìˆëŠ” ID ëª©ë¡ì„ ê°€ì ¸ì™€ ì¤‘ë³µ ë°ì´í„° í•„í„°ë§
        existing_ids_df = hook.get_pandas_df(sql="SELECT id FROM job_posts")
        if not existing_ids_df.empty:
            existing_ids_set = set(existing_ids_df['id'])
            mask = ~final_data['id'].isin(existing_ids_set)
            new_data_to_insert = final_data[mask]
        else:
            new_data_to_insert = final_data
            
        print(f"ê¸°ì¡´ ë°ì´í„°ì™€ ë¹„êµ í›„, {len(new_data_to_insert)}ê°œì˜ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"ğŸš¨ DBì—ì„œ ê¸°ì¡´ IDë¥¼ í™•ì¸í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ëª¨ë“  ë°ì´í„°ë¥¼ ì €ì¥ ì‹œë„í•©ë‹ˆë‹¤.")
        new_data_to_insert = final_data

    if new_data_to_insert.empty:
        print("ìƒˆë¡­ê²Œ ì¶”ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        # Airflow Hookì˜ ê³µì‹ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        rows_to_insert = list(new_data_to_insert.itertuples(index=False, name=None))
        target_fields = list(new_data_to_insert.columns)
        
        hook.insert_rows(
            table="job_posts",
            rows=rows_to_insert,
            target_fields=target_fields,
            commit_every=1000  # 1000ê°œì”© ë‚˜ëˆ ì„œ ì»¤ë°‹í•˜ì—¬ ì•ˆì •ì„± í–¥ìƒ
        )
        print(f"ğŸ‰ ì„±ê³µ! {len(new_data_to_insert)}ê°œì˜ ë°ì´í„°ê°€ 'job_posts' í…Œì´ë¸”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ğŸš¨ ìµœì¢… ë°ì´í„°ë¥¼ DBì— ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise